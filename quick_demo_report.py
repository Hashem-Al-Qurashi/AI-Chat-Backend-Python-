#!/usr/bin/env python3
"""
Quick demo that generates a sample report showing what the full test produces
"""

import requests
import time
from datetime import datetime

API_BASE = "http://localhost:8001"

def quick_demo():
    """Generate a quick demonstration report"""
    
    user_id = "quick_demo_user"
    
    # Key messages to show stage progression
    demo_messages = [
        # Stage 1
        "Hi! I'm Alex, a software developer working from home.",
        "I'm having trouble staying focused during coding sessions.",
        
        # Stage 2 - Start coffee mentions
        "I love drinking coffee while I code - it helps me focus.",
        "My morning coffee ritual is sacred to me.",
        "I usually have 3-4 cups of coffee during a work day.",
        "Coffee and coding go hand in hand for me.",
        
        # Show preference detection
        "Do you have any coffee recommendations for my coding sessions?"
    ]
    
    report_lines = []
    report_lines.append("ğŸ§  AI MEMORY BACKEND - QUICK DEMONSTRATION REPORT")
    report_lines.append("=" * 70)
    report_lines.append(f"Generated: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    report_lines.append(f"User ID: {user_id}")
    report_lines.append("")
    report_lines.append("This demonstrates the AI Memory Backend evolution:")
    report_lines.append("")
    
    for i, message in enumerate(demo_messages, 1):
        print(f"Processing message {i}...")
        
        report_lines.append(f"ğŸ’¬ MESSAGE {i}: {message}")
        report_lines.append("")
        
        try:
            data = {
                "userId": user_id,
                "message": message,
                "config": {"temperature": 0.7, "maxTokens": 150}
            }
            
            response = requests.post(f"{API_BASE}/chat", json=data, timeout=30)
            
            if response.status_code == 200:
                result = response.json()
                
                ai_response = result.get('response', 'No response')
                stage = result.get('stage', 'Unknown')
                conv_count = result.get('conversationCount', 0)
                
                report_lines.append(f"ğŸ¤– AI RESPONSE ({stage}):")
                report_lines.append(f"   {ai_response}")
                report_lines.append("")
                report_lines.append(f"ğŸ“Š Conversation Count: {conv_count}")
                
                # Show memory nodes
                memory_used = result.get('memoryUsed', [])
                if memory_used:
                    report_lines.append("ğŸ§  Memory Nodes Used:")
                    for node in memory_used[:3]:
                        node_type = node.get('type', 'Unknown')
                        content = (node.get('content') or '')[:40]
                        weight = node.get('weight')
                        if weight is not None:
                            report_lines.append(f"   â€¢ {node_type}: {content}... (weight: {weight:.2f})")
                        else:
                            report_lines.append(f"   â€¢ {node_type}: {content}...")
                
            elif response.status_code == 429:
                report_lines.append("âš ï¸  Rate limit reached - continuing...")
                time.sleep(5)
                
            else:
                report_lines.append(f"âŒ Error: {response.status_code}")
                
        except Exception as e:
            report_lines.append(f"âŒ Request failed: {e}")
        
        report_lines.append("")
        report_lines.append("-" * 50)
        report_lines.append("")
        
        time.sleep(2)  # Wait between messages
    
    # Get final memory state
    try:
        response = requests.get(f"{API_BASE}/memory/{user_id}")
        if response.status_code == 200:
            memory = response.json()
            
            report_lines.append("")
            report_lines.append("ğŸ§  FINAL MEMORY STATE")
            report_lines.append("=" * 50)
            report_lines.append(f"User: {user_id}")
            report_lines.append(f"Stage: {memory.get('stage')}")
            report_lines.append(f"Conversations: {memory.get('conversationCount')}")
            
            stats = memory.get('graphStats', {})
            report_lines.append("ğŸ“Š Graph Statistics:")
            report_lines.append(f"  Nodes: {stats.get('total_nodes', 0)}")
            report_lines.append(f"  Edges: {stats.get('total_edges', 0)}")
            report_lines.append(f"  Messages: {stats.get('message_count', 0)}")
            
            prefs = memory.get('topPreferences', [])
            if prefs:
                report_lines.append("ğŸ” Top Preferences:")
                for pref in prefs:
                    keyword = pref.get('keyword', 'N/A')
                    weight = pref.get('weight', 0)
                    count = pref.get('count', 0)
                    report_lines.append(f"  â€¢ {keyword}")
                    report_lines.append(f"    Weight: {weight:.2f} | Count: {count}")
            else:
                report_lines.append("ğŸ” No preferences detected yet")
                
            report_lines.append("")
            report_lines.append("ğŸ’¡ Memory Evolution:")
            report_lines.append("Stage 1 (1-4 msgs): Basic history")
            report_lines.append("Stage 2 (5-14 msgs): Keyword tracking")
            report_lines.append("Stage 3 (15-29 msgs): Relationship weighting")
            report_lines.append("Stage 4 (30+ msgs): Advanced contextual search")
            
    except Exception as e:
        report_lines.append(f"âŒ Memory state error: {e}")
    
    report_lines.append("")
    report_lines.append("âœ… KEY FEATURES DEMONSTRATED:")
    report_lines.append("â€¢ Stage progression based on conversation count")
    report_lines.append("â€¢ Keyword preference detection (coffee)")
    report_lines.append("â€¢ Graph database with nodes and edges")
    report_lines.append("â€¢ AI responses referencing user preferences")
    report_lines.append("â€¢ Memory nodes influencing responses")
    report_lines.append("")
    report_lines.append("This is exactly what the client requested:")
    report_lines.append("ğŸ“Š Graph-based memory with evolving intelligence")
    report_lines.append("ğŸ¤– Personalized AI responses")
    report_lines.append("ğŸ§  Memory that grows smarter over time")
    
    # Save report
    report_content = "\n".join(report_lines)
    
    try:
        with open("quick_demo_report.txt", 'w', encoding='utf-8') as f:
            f.write(report_content)
        print("âœ… Quick demo report saved to quick_demo_report.txt")
    except Exception as e:
        print(f"âŒ Error saving: {e}")
    
    return report_content

if __name__ == "__main__":
    print("ğŸš€ Running Quick Demo...")
    report = quick_demo()
    print("âœ… Demo complete!")
    print("ğŸ“ Report saved as: quick_demo_report.txt")